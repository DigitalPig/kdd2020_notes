# Hands On Tutorial: Dealing with Bias and Fairness in Data Science Systems: A Practical Hands-on Tutorial

[Repo](https://dssg.github.io/fairness_tutorial/) and [Tutorial Video version 1](https://youtu.be/VJVu1zgp6m4), [Tutorial Video Version 2](https://vimeo.com/445621372), and [Slide](https://docs.google.com/presentation/d/146n8pyvkbZ8sS0WA3Jixb6hNGTcaD31HMuX7HRjk1rE/edit#slide=id.g8d5290cc44_0_0)

Related tool [Aequitas](http://www.datasciencepublicpolicy.org/projects/aequitas/)

Bias can be everywhere, not only in the data, but also in the model that we trained.

The interesting thing is the Fairness Tree that authors proposed:

![Fairness Tree](http://www.datasciencepublicpolicy.org/wp-content/uploads/2020/02/Fairness-Weeds.png)

